# web_scrape-challenge
For this challenge, automated browsing is used to scrape data from websites with articles and data about Mars. The data is then converted to a dataframe to conduct data analysis, answer questions and create plots.

The analysis and plots are located in two jupyter notebooks, and the resulting dataset was exported to a csv, file saved into the resources folder.




 Sources: Some of the code used to perform this analysis was inspired by various sources on github.